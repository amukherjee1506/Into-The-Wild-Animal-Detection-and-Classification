{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "# from future import print_function\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from data import COCO_ROOT, COCO_CLASSES as labelmap\n",
    "from PIL import Image\n",
    "from data import VOCAnnotationTransform, VOCDetection, BaseTransform, VOC_CLASSES\n",
    "from data import COCO_CLASSES, COCOAnnotationTransform, COCODetection\n",
    "import torch.utils.data as data\n",
    "from ssd import build_ssd\n",
    "\n",
    "COCO_change_category = [0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 16, 21, 30, 33, 34, 51, 99]\n",
    "COCO_change_category = [str(i) for i in COCO_change_category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Single Shot MultiBox Detection')\n",
    "parser.add_argument('--trained_model', default='weights/ssd300_COCO_RES_28000.pth',\n",
    "type=str, help='Trained state_dict file path to open')\n",
    "parser.add_argument('--save_folder', default='eval/', type=str,\n",
    "help='Dir to save results')\n",
    "parser.add_argument('--visual_threshold', default=0.25, type=float,\n",
    "help='Final confidence threshold')\n",
    "parser.add_argument('--cuda', default=True, type=bool,\n",
    "help='Use cuda to train model')\n",
    "parser.add_argument('--coco_root', default=COCO_ROOT, help='Location of VOC root directory')\n",
    "parser.add_argument('-f', default=None, type=str, help=\"Dummy arg so we can load in Jupyter Notebooks\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.cuda and torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "if not os.path.exists(args.save_folder):\n",
    "    os.mkdir(args.save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.2f')\n",
    "\n",
    "def test_net(save_folder, net, cuda, testset, transform, thresh):\n",
    "# dump predictions and assoc. ground truth to text file for now\n",
    "    filename = save_folder + 'result_part_a.json'\n",
    "    num_images = len(testset)\n",
    "    Final_list = []\n",
    "\n",
    "    for i in range(num_images):\n",
    "        if i%100==0:\n",
    "            print('Testing image {:d}/{:d}....'.format(i+1, num_images))\n",
    "        img = testset.pull_image(i)\n",
    "        x = torch.from_numpy(transform(img)[0]).permute(2, 0, 1)\n",
    "        x = Variable(x.unsqueeze(0))\n",
    "\n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "\n",
    "        y = net(x)      # forward pass\n",
    "        detections = y.data\n",
    "        # scale each detection back up to the image\n",
    "        scale = torch.Tensor([img.shape[1], img.shape[0],\n",
    "                             img.shape[1], img.shape[0]])\n",
    "\n",
    "        # ii -> category id\n",
    "        for ii in range(detections.size(1)):\n",
    "            j = 0\n",
    "            while detections[0, ii, j, 0] >= thresh:\n",
    "\n",
    "                score = detections[0, ii, j, 0].cpu().data.numpy()\n",
    "                pt = (detections[0, ii, j, 1:]*scale).cpu().numpy()\n",
    "                coords = (pt[0], pt[1], pt[2], pt[3])\n",
    "\n",
    "                # standard format of coco ->\n",
    "                # [{\"image_id\":42,\"category_id\":18,\"bbox\":[258.15,41.29,348.26,243.78],\"score\":0.236},{...},...]\n",
    "                temp_dict = {}\n",
    "\n",
    "#                     print(COCO_change_category)\n",
    "#                     print(ii)\n",
    "\n",
    "#                     print(\n",
    "#                             '{\"image_id\":' + str(testset.pull_anno(i)[0]['image_id']) +\n",
    "#                             ',\"category_id\":' + str(COCO_change_category[ii]) +\n",
    "#                             ',\"bbox\":[' + ','.join(str(c) for c in coords) + ']'\n",
    "#                             ',\"score\":', '%.2f' %(score), '},')\n",
    "\n",
    "                temp_dict[\"image_id\"] = str(testset.pull_anno(i)[0]['image_id'])\n",
    "                temp_dict[\"category_id\"] = float(COCO_change_category[ii])\n",
    "                temp_dict[\"bbox\"] = [float(c) for c in coords]\n",
    "                temp_dict[\"score\"] = float(score)\n",
    "\n",
    "                Final_list.append(temp_dict)\n",
    "                j += 1\n",
    "    import json\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(Final_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_voc():\n",
    "# load net\n",
    "    num_classes = 17 # change\n",
    "    net = build_ssd('test', 300, num_classes) # initialize SSD\n",
    "    net.load_state_dict(torch.load(args.trained_model))\n",
    "    net.eval()\n",
    "    print('Finished loading model!')\n",
    "    # load data\n",
    "    testset = COCODetection(args.coco_root, None, COCOAnnotationTransform)\n",
    "    if args.cuda:\n",
    "        net = net.cuda()\n",
    "        cudnn.benchmark = True\n",
    "    # evaluation\n",
    "    test_net(args.save_folder, net, args.cuda, testset,\n",
    "    BaseTransform(net.size, (104, 117, 123)),\n",
    "    thresh=args.visual_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False), Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6)), ReLU(inplace), Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1)), ReLU(inplace)]\n",
      "Finished loading model!\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Testing image 1/12099....\n",
      "Testing image 101/12099....\n",
      "Testing image 201/12099....\n",
      "Testing image 301/12099....\n",
      "Testing image 401/12099....\n",
      "Testing image 501/12099....\n",
      "Testing image 601/12099....\n",
      "Testing image 701/12099....\n",
      "Testing image 801/12099....\n",
      "Testing image 901/12099....\n",
      "Testing image 1001/12099....\n",
      "Testing image 1101/12099....\n",
      "Testing image 1201/12099....\n",
      "Testing image 1301/12099....\n",
      "Testing image 1401/12099....\n",
      "Testing image 1501/12099....\n",
      "Testing image 1601/12099....\n",
      "Testing image 1701/12099....\n",
      "Testing image 1801/12099....\n",
      "Testing image 1901/12099....\n",
      "Testing image 2001/12099....\n",
      "Testing image 2101/12099....\n",
      "Testing image 2201/12099....\n",
      "Testing image 2301/12099....\n",
      "Testing image 2401/12099....\n",
      "Testing image 2501/12099....\n",
      "Testing image 2601/12099....\n",
      "Testing image 2701/12099....\n",
      "Testing image 2801/12099....\n",
      "Testing image 2901/12099....\n",
      "Testing image 3001/12099....\n",
      "Testing image 3101/12099....\n",
      "Testing image 3201/12099....\n",
      "Testing image 3301/12099....\n",
      "Testing image 3401/12099....\n",
      "Testing image 3501/12099....\n",
      "Testing image 3601/12099....\n",
      "Testing image 3701/12099....\n",
      "Testing image 3801/12099....\n",
      "Testing image 3901/12099....\n",
      "Testing image 4001/12099....\n",
      "Testing image 4101/12099....\n",
      "Testing image 4201/12099....\n",
      "Testing image 4301/12099....\n",
      "Testing image 4401/12099....\n",
      "Testing image 4501/12099....\n",
      "Testing image 4601/12099....\n",
      "Testing image 4701/12099....\n",
      "Testing image 4801/12099....\n",
      "Testing image 4901/12099....\n",
      "Testing image 5001/12099....\n",
      "Testing image 5101/12099....\n",
      "Testing image 5201/12099....\n",
      "Testing image 5301/12099....\n",
      "Testing image 5401/12099....\n",
      "Testing image 5501/12099....\n",
      "Testing image 5601/12099....\n",
      "Testing image 5701/12099....\n",
      "Testing image 5801/12099....\n",
      "Testing image 5901/12099....\n",
      "Testing image 6001/12099....\n",
      "Testing image 6101/12099....\n",
      "Testing image 6201/12099....\n",
      "Testing image 6301/12099....\n",
      "Testing image 6401/12099....\n",
      "Testing image 6501/12099....\n",
      "Testing image 6601/12099....\n",
      "Testing image 6701/12099....\n",
      "Testing image 6801/12099....\n",
      "Testing image 6901/12099....\n",
      "Testing image 7001/12099....\n",
      "Testing image 7101/12099....\n",
      "Testing image 7201/12099....\n",
      "Testing image 7301/12099....\n",
      "Testing image 7401/12099....\n",
      "Testing image 7501/12099....\n",
      "Testing image 7601/12099....\n",
      "Testing image 7701/12099....\n",
      "Testing image 7801/12099....\n",
      "Testing image 7901/12099....\n",
      "Testing image 8001/12099....\n",
      "Testing image 8101/12099....\n",
      "Testing image 8201/12099....\n",
      "Testing image 8301/12099....\n",
      "Testing image 8401/12099....\n",
      "Testing image 8501/12099....\n",
      "Testing image 8601/12099....\n",
      "Testing image 8701/12099....\n",
      "Testing image 8801/12099....\n",
      "Testing image 8901/12099....\n",
      "Testing image 9001/12099....\n",
      "Testing image 9101/12099....\n",
      "Testing image 9201/12099....\n",
      "Testing image 9301/12099....\n",
      "Testing image 9401/12099....\n",
      "Testing image 9501/12099....\n",
      "Testing image 9601/12099....\n",
      "Testing image 9701/12099....\n",
      "Testing image 9801/12099....\n",
      "Testing image 9901/12099....\n",
      "Testing image 10001/12099....\n",
      "Testing image 10101/12099....\n",
      "Testing image 10201/12099....\n",
      "Testing image 10301/12099....\n",
      "Testing image 10401/12099....\n",
      "Testing image 10501/12099....\n",
      "Testing image 10601/12099....\n",
      "Testing image 10701/12099....\n",
      "Testing image 10801/12099....\n",
      "Testing image 10901/12099....\n",
      "Testing image 11001/12099....\n",
      "Testing image 11101/12099....\n",
      "Testing image 11201/12099....\n",
      "Testing image 11301/12099....\n",
      "Testing image 11401/12099....\n",
      "Testing image 11501/12099....\n",
      "Testing image 11601/12099....\n",
      "Testing image 11701/12099....\n",
      "Testing image 11801/12099....\n",
      "Testing image 11901/12099....\n",
      "Testing image 12001/12099....\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    test_voc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
